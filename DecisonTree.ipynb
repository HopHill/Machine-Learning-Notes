{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 决策树算法知识点"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树算法的常用算法\n",
    "最初的决策树算法是心理学家兼计算机科学家E.B.Hunt于1962年在研究人类的概念学习过程中提出的CLS（Concept Learning System）\n",
    "ID3算法，由罗斯·昆兰于1979年提出，1986年完善，最优划分属性的判别指标：信息增益。\n",
    "\n",
    "C4.5算法，由罗斯昆兰于1993年提出，该算法是ID3算法的改进，使用了一个启发式方法：先从候选划分属性中找出信息增益高于平均水平的属性，再从中选择信息增益率最高的。同时，C4.5算法在树构造过程中进行剪枝防止过拟合，能够完成对连续属性的离散化处理以及能够对不完整数据进行处理。\n",
    "\n",
    "CART算法，分类回归树算法，由Breiman于1984年提出，该算法既能用于分类任务，也能用于预测任务决策树算法的原理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树算法的原理\n",
    "\n",
    "是基于树结构进行决策，决策树的生成过程是一个递归的过程。通过选择最优划分属性，将样本划分到使得“纯度提升”最大的类别中去。一般的，一颗决策树\n",
    "包含一个根节点，若干分支节点（内部节点）和若干叶节点，，叶节点对应于决策结果，其他节点对应于一个属性测试。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树算法的一般流程\n",
    "\n",
    "输入：训练集={（x1,y1）,(x2,y2),……，（xm,ym）}\n",
    "属性集={a1,a2,……,ad}\n",
    "\n",
    "过程：函数TreeGenerate(D,A)\n",
    "\n",
    "1.生成节点Node;\n",
    "\n",
    "2.If D中样本属于同一类别C then\n",
    "\n",
    "3.将Node标记为C类叶节点；return\n",
    "\n",
    "4.End if\n",
    "\n",
    "5.If A=∅ or D中样本在A上取值相同 then\n",
    "\n",
    "6.将Node标记为叶节点，其类别标记为D中样本数最多的类；return\n",
    "\n",
    "7.End if\n",
    "\n",
    "8.从A中选择最优划分属性a*\n",
    "\n",
    "9.For a* in a*v:\n",
    "\n",
    "10.为Node生成一个分支；令Dv表示D中在a*上取值为a*v的样本子集；\n",
    "\n",
    "11.   If Dv为空 then\n",
    "\n",
    "12.       将分支节点标记为叶节点，其类别标记为D中样本数最多的类；return\n",
    "\n",
    "13.   Else\n",
    "\n",
    "14.       以TreeGenerate(Dv,A\\{a*})为分支结点\n",
    "\n",
    "15.   End if\n",
    "\n",
    "16.End for\n",
    "\n",
    "输出：以Node为根节点的一颗决策树\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树算法的优点\n",
    "决策树算法对原始数据集的处理工作要求较少，对缺失值不敏感，可以处理不相关特征数据\n",
    "\n",
    "决策树算法不仅可以用于二分类，也可以用于多分类\n",
    "\n",
    "决策树算法可以应用于混合属性的数据集\n",
    "\n",
    "以树的结构展示逻辑关系，符合人类的直觉认识，有助于理解数据\n",
    "\n",
    "在相对短的时间内能够对大型数据集作出可行且效果良好的结果\n",
    "\n",
    "效率高，决策树只需一次构建，反复使用，每一次预测的最大计算次数不超过决策树的深度\n",
    "\n",
    "是很多集成学习方法的基学习器，如随机森林、GBDT\n",
    "\n",
    "Reference:\n",
    "https://blog.csdn.net/keepreder/article/details/47168383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树算法的缺点\n",
    "\n",
    "容易产生过拟合，，属于高方差低偏差模型，对数据集中数据的微小变化比较敏感。可以通过剪枝等方式防止过拟合，剪枝分为预剪枝和后剪枝\n",
    "\n",
    "对连续性的属性比较难预测\n",
    "\n",
    "对有时间顺序的数据，需要很多预处理的工作\n",
    "\n",
    "当类别太多时，错误可能增加的比较快\n",
    "\n",
    "在处理特征关联性比较强的数据时表现不是太好\n",
    "\n",
    "Reference:\n",
    "https://blog.csdn.net/keepreder/article/details/47168383"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 决策树算法在现实世界的应用\n",
    "\n",
    "一些趣味问答游戏，通过提问问题，用户给出答案，判定某个结果属于哪个类别"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn中的决策树模块的一般使用流程\n",
    "\n",
    "from sklearn.tree import DecisionTreeClssifiler#导入分类库\n",
    "\n",
    "Param = {“max_depth”:4}#设置参数\n",
    "\n",
    "clf_model = DecisionTreeClssifiler()#构建模型\n",
    "\n",
    "clf_model.fit(train_X,train_y)#在训练集上训练模型\n",
    "\n",
    "pred_y=clf_model.predict(test_X)#在测试集上预测\n",
    "\n",
    "注:sklearn中关于决策树模型的默认设置\n",
    "class sklearn.tree.DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, \n",
    "                                            min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, \n",
    "                                            max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, \n",
    "                                            min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
    "\n",
    "reference:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html?highlight=decisiontree#sklearn.tree.DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#导入需要的库\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "iris = load_iris()\n",
    "data = iris.data\n",
    "targets = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#划分数据集\n",
    "train_X,test_X,train_y,test_y = train_test_split(data,targets,test_size=0.2,random_state=42)\n",
    "\n",
    "#构建决策树\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_y = clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  9,  0],\n",
       "       [ 0,  0, 11]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(test_y,preds_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90243902, 0.9       , 0.94871795])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(clf,train_X,train_y,cv=3,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 延伸：实施交叉验证的不同方式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method_1:高阶方法：\n",
    "\n",
    "直接使用sklearn.model_selection中的交叉验证功能cross_val_score,cross_val_score()函数返回的是K折交叉验证的K次分值的数组，至于分值是什么，取决于你的目标和scoring参数设置的值，对于预测类任务，scoring='neg_mean_squared_error'，对于分类任务，scoring='accuracy'。\n",
    "\n",
    "例如："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.93333333, 1.        , 0.93333333, 0.93333333,\n",
       "       0.86666667, 0.93333333, 1.        , 1.        , 1.        ])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "iris = load_iris()\n",
    "clf=DecisionTreeClassifier(random_state=0)\n",
    "cross_val_score(clf,iris.data,iris.target,scoring='accuracy',cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method_2:低阶方法：\n",
    "\n",
    "cross_val_score（）这一类交叉验证的函数，直接输出交叉验证的结果，但有时你可能希望自己能控制的多一些，在这种情况下，你可以自行实施交叉验证，\n",
    "并输出相应的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
